no = ((1.96 * sd) / 3)^2    # Correct formula for sample size
# Sample size (no adjustment needed based on the current sample length)
d=no/length(Total.Time.Spent)
n=no/(1+d)
n
vari = var(Income)  # Variance of the Total Time Spent
sd = sqrt(vari)               # Standard deviation
MOE = 1.96 * sd               # MoE calculation with Z = 1.96 for 95% confidence level
no = ((1.96 * sd) / 3)^2    # Correct formula for sample size
# Sample size (no adjustment needed based on the current sample length)
d=no/length(income)
# Sample size (no adjustment needed based on the current sample length)
d=no/length(Income)
n=no/(1+d)
n
vari = var(Income)  # Variance of the Total Time Spent
sd = sqrt(vari)               # Standard deviation
MOE = 1.96 * sd               # MoE calculation with Z = 1.96 for 95% confidence level
no = ((1.96 * sd) / 3)^2    # Correct formula for sample size
# Sample size (no adjustment needed based on the current sample length)
d=no/length(Income)
n=no/(1+d)
n
vari = var(Income)             # Variance of the Total Time Spent
sd = sqrt(vari)                # Standard deviation
E = 3                          # Desired Margin of Error
Z = 1.96                       # Z-score for 95% confidence level
n0 = (Z * sd / E)^2           # Sample size calculation
n0
d=no/length(Income)
n=no/(1+d)
n
d=n0/length(Income)
n=n0/(1+d)
n
n=rsampcalc(nrow(data),e=3,ci=95)
n
range_values <- range(Total.Time.Spent)
range_values
min=min(Time.Wasters.on.Social.Media)
min=min(Total.Time.Spent)
min
max=max(Total.Time.Spent)
max
range=max-min
s1=range/6
s2=range/4
n0 = (Z * s1 / E)^2           # Sample size calculation
min=min(Total.Time.Spent)
min
min
max=max(Total.Time.Spent)
max
range=max-min
s1=range/6
s2=range/4
E = 3                          # Desired Margin of Error
Z = 1.96                       # Z-score for 95% confidence level
n0 = (Z * s1 / E)^2           # Sample size calculation
n=(n0+(1+(n0/length(Total.Time.Spent))))
n
length(Total.Time.Spent)
n0
min=min(Total.Time.Spent)
min
min
max=max(Total.Time.Spent)
max
range=max-min
s1=range/6
s2=range/4
E = 3                          # Desired Margin of Error
Z = 1.96                       # Z-score for 95% confidence level
n0 = ((Z * s1) / E))*((Z * s1) / E))          # Sample size calculation
n0
n=(n0+(1+(n0/length(Total.Time.Spent))))
n0 = ((Z * s1) / E)*((Z * s1) / E)          # Sample size calculation
n0
n0 = ((Z * s2) / E)*((Z * s2) / E)          # Sample size calculation
n0
n=(n0+(1+(n0/length(Total.Time.Spent))))
n
length(Total.Time.Spent)
n0 = ((Z * s1) / 10)*((Z * s1) / 10)          # Sample size calculation
n0
n=(n0+(1+(n0/length(Total.Time.Spent))))
n
length(Total.Time.Spent)
most_used_beauty_cosmetics_products_extended <- read.csv("C:/Users/LENOVO/Desktop/is_project/most_used_beauty_cosmetics_products_extended.csv")
View(most_used_beauty_cosmetics_products_extended)
attach(most_used_beauty_cosmetics_products_extended)
data=most_used_beauty_cosmetics_products_extended
library(sampler)
# Assuming these values:
z <- 1.96  # Z-value for 95% confidence level
margin_error <- 10  # Desired margin of error (e.g., $10)
sigma <- sd(data$Price_USD, na.rm = TRUE)  # Estimate population standard deviation from sample
# Sample size calculation
n_mean <- (z * sigma / margin_error)^2
ceiling(n_mean)  # Round up to the nearest whole number
n=(n_mean/(1+(n_mean/length(Price_USD))))
n
library(sampler)
# Assuming these values:
z <- 1.96  # Z-value for 95% confidence level
margin_error <- 3  # Desired margin of error (e.g., $10)
sigma <- sd(data$Price_USD, na.rm = TRUE)  # Estimate population standard deviation from sample
# Sample size calculation
n_mean <- (z * sigma / margin_error)^2
ceiling(n_mean)  # Round up to the nearest whole number
n=(n_mean/(1+(n_mean/length(Price_USD))))
n
most_used_beauty_cosmetics_products_extended <- read.csv("C:/Users/LENOVO/Desktop/is_project/most_used_beauty_cosmetics_products_extended.csv")
View(most_used_beauty_cosmetics_products_extended)
attach(most_used_beauty_cosmetics_products_extended)
data=most_used_beauty_cosmetics_products_extended
library(sampler)
# Assuming these values:
z <- 1.96  # Z-value for 95% confidence level
margin_error <- 3  # Desired margin of error (e.g., $10)
sigma <- sd(data$Price_USD, na.rm = TRUE)  # Estimate population standard deviation from sample
# Sample size calculation
n_mean <- (z * sigma / margin_error)^2
ceiling(n_mean)  # Round up to the nearest whole number
n=(n_mean/(1+(n_mean/length(Price_USD))))
n
library(sampler)
z <- 1.96  # Z-value for 95% confidence level
margin_error <- 3  # Desired margin of error
sigma <- sd(data$Price_USD, na.rm = TRUE)  # Estimate population standard deviation from sample
# Sample size calculation
n0 <- (z * sigma / margin_error)^2
ceiling(n0)  # Round up to the nearest whole number
n=(n0/(1+(n0/length(Price_USD))))
n
#get random sample 1 for the SRS
set.seed(12345)  # ensure that same random sample generate every time
#Create a data frame
data1=data.frame(dataset)
#Create a data frame
data1=data.frame(data)
attach(data1)
#Identifying missing values in the dataset
!is.na(data1)
data1$Brand= as.factor(data1$Brand)
data1$Brand= as.factor(data1$Brand)
data1$Category= as.factor(data1$Category)
data1$Usage_Frequency= as.factor(data1$Usage_Frequency)
data1$Skin_Type= as.factor(data1$Skin_Type)
data1$Gender_Target= as.factor(data1$Gender_Target)
data1$Packaging_Type= as.factor(data1$Packaging_Type)
data1$Main_Ingredient= as.factor(data1$Main_Ingredient)
data1$Cruelty_Free= as.factor(data1$Cruelty_Free)
data1$Country_of_Origin= as.factor(data1$Country_of_Origin)
summary(data1)
summary(data1)
#install.packages("sampler")
library(sampler)
z <- 1.96  # Z-value for 95% confidence level
margin_error <- 3  # Desired margin of error
sigma <- sd(data1$Price_USD, na.rm = TRUE)  # Estimate population standard deviation from sample
# Sample size calculation
n0 <- (z * sigma / margin_error)^2
ceiling(n0)  # Round up to the nearest whole number
n=(n0/(1+(n0/length(Price_USD))))
n
n=ceiling(n)
n
#get random sample 1 for the SRS
set.seed(12345)  # ensure that same random sample generate every time
sample_SRS1 = rsamp(data1,n,rep=FALSE)
View(sample1_SRS1)
View(sample_SRS1)
#estimates
install.packages("survey")
library(survey)
#defining survey object
sample_SRS1_design = svydesign(id=~1, weights = sample_SRS1$weight, data = sample_SRS1)
#estimates for price
SRS1_meanprice = svymean(~Price_USD,sample_SRS1_design)
SRS1_meanprice
SRS1_totalprice = svytotal(~Price_USD,sample_SRS1_design)
SRS1_totalprice
#estimates for price
SRS1_meanrate = svymean(~Rating,sample_SRS1_design)
SRS1_meanrate
SRS1_totalrate = svytotal(~Rating,sample_SRS1_design)
SRS1_totalrate
#estimates for reviews
SRS1_meanreviews = svymean(~Number_of_Reviews,sample_SRS1_design)
SRS1_meanreviews
SRS1_totalreviews = svytotal(~Number_of_Reviews,sample_SRS1_design)
SRS1_totalreviews
#estimates for product size
SRS1_meanproductsize = svymean(~Product_Size,sample_SRS1_design)
SRS1_meanproductsize
SRS1_totalproductsize = svytotal(~Product_Size,sample_SRS1_design)
SRS1_totalproductsize
data1$Product_Size=as.factor(data1$Product_Size)
#Estimating the proportion of brand
SRS_1_Brand = svymean(~Brand, sample_SRS1_design)
SRS_1_Brand
SRS_1_Brand
SRS_1_Brand
SRS_1_Brand
SRS_1_Brand
SRS_1_Category = svymean(~Category, sample_SRS1_design)
SRS_1_Category
SRS_1_Category = svymean(~Usage_Frequency, sample_SRS1_design)
SRS_1_Category
SRS_1_Product_size = svymean(~Product_size, sample_SRS1_design)
SRS_1_Product_size
SRS_1_Category = svymean(~Category, sample_SRS1_design)
SRS_1_Category
SRS_1_Usagefrequency = svymean(~Usage_Frequency, sample_SRS1_design)
SRS_1_Usagefrequency
SRS_1_Productsize = svymean(~Product_Size, sample_SRS1_design)
SRS_1_Productsize
SRS_1_skintype = svymean(~Skin_Type, sample_SRS1_design)
SRS_1_skintype
SRS_1_gender = svymean(~Gender_Target, sample_SRS1_design)
SRS_1_gender
SRS_1_packtype = svymean(~Packaging_Type, sample_SRS1_design)
SRS_1_packtype
SRS_1_ingredient = svymean(~Main_Ingredient, sample_SRS1_design)
SRS_1_ingredient
SRS_1_crueltyfree = svymean(~Cruelty_Free, sample_SRS1_design)
SRS_1_crueltyfree
SRS_1_country = svymean(~Country_of_Origin, sample_SRS1_design)
SRS_1_country
###########population parameters-----------------------------------------------------------------------
pop_price_mean = mean(data1$Price_USD)
pop_price_total = sum(data1$Price_USD)
pop_price_mean
pop_price_total = sum(data1$Price_USD)
pop_price_total
pop_rating_mean=mean(data1$Rating)
pop_rating_mean
pop_reviews_mean=mean(data1$Number_of_Reviews)
pop_reviews_mean
pop_rating_sum= sum(data1$Rating)
pop_rating_total= sum(data1$Rating)
pop_rating_total
pop_reviews_total= sum(data1$Number_of_Reviews)
pop_reviews_total
pop_brand_proportion =
data.frame(table(data1$Brand)/length(data1$Brand))
pop_brand_proportion =data.frame(table(data1$Brand)/length(data1$Brand))
pop_brand_proportion
pop_Category_proportion=data.frame(table(data1$Category)/length(data1$Category))
pop_Category_proportion
pop_usage_proportion=data.frame(table(data1$Usage_Frequency)/length(data1$Usage_Frequency))
pop_usage_proportion
pop_Category_proportion=data.frame(table(data1$Category)/length(data1$Category))
pop_Category_proportion
pop_productsize_proportion=data.frame(table(data1$Product_Size)/length(data1$Category))
pop_productsize_proportion
pop_productsize_proportion
pop_country_proportion=data.frame(table(data1$Country_of_Origin)/length(data1$Category))
pop_country_proportion
pop_usage_proportion=data.frame(table(data1$Usage_Frequency)/length(data1$Usage_Frequency))
pop_usage_proportion
pop_productsize_proportion=data.frame(table(data1$Product_Size)/length(data1$Category))
pop_productsize_proportion
pop_skin_proportion=data.frame(table(data1$Skin_Type)/length(data1$Category))
pop_skin_proportion
pop_gender_proportion=data.frame(table(data1$Product_Size)/length(data1$Category))
pop_gender_proportion
pop_ingredient_proportion=data.frame(table(data1$Main_Ingredient)/length(data1$Category))
pop_ingredient_proportion
pop_cruelty_proportion=data.frame(table(data1$Cruelty_Free)/length(data1$Category))
pop_cruetlty_proportion
pop_country_proportion=data.frame(table(data1$Country_of_Origin)/length(data1$Category))
pop_country_proportion
pop_cruelty_proportion
pop_country_proportion=data.frame(table(data1$Country_of_Origin)/length(data1$Category))
pop_country_proportion
#######comparison-------------------------------------------------------------------------
comp1_SRS1= data.frame(Statistic=c("Price_MEAN", "Price_TOTAL"), SRS1=
c(SRS1_meanprice,SRS1_totalprice),
Population= c(pop_price_mean, pop_price_total))
comp1_SRS1
#######comparison-------------------------------------------------------------------------
comp1_SRS1= data.frame(Statistic=c("Price_MEAN", "Price_TOTAL"), SRS1=c(SRS1_meanprice,SRS1_totalprice),Population= c(pop_price_mean, pop_price_total))
comp1_SRS1
SpeedyCall.Customer.Churn.Data <- read.csv("D:/3rdyr_2nd_sem/IS 3005/week1/SpeedyCall Customer Churn Data.xlsx", sep="", stringsAsFactors=TRUE)
View(SpeedyCall.Customer.Churn.Data)
SpeedyCall.Customer.Churn.Data...Copy <- read.csv("D:/3rdyr_2nd_sem/IS 3005/week1/SpeedyCall Customer Churn Data - Copy.xlsx", sep="", stringsAsFactors=TRUE)
View(SpeedyCall.Customer.Churn.Data...Copy)
PCA_ex01 <- read.csv("D:/3rdyr_2nd_sem/IS 3004/week9/PCA examples/PCA_ex01.csv")
View(PCA_ex01)
# Reading the data into R
pca_ex01 = read.csv("PCA_ex01.csv", header=TRUE)
# Reading the data into R
pca_ex01 = read.csv("PCA_ex01", header=TRUE)
# Reading the data into R
pca_ex01 = attach("PCA_ex01.csv", header=TRUE)
# Reading the data into R
pca_ex01 = attach("PCA_ex01.csv")
# Reading the data into R
# Import dataset (CSV file)
data <- read.csv("your_dataset.csv")
# Reading the data into R
# Import dataset (CSV file)
data <- read.csv("PCA_ex01.csv")
# Attach the dataset
attach(data)
fix(pca_ex01)
fix(pca_ex01)
names(pca_ex01)[1]="Income"
# Attach the dataset
attach(data)
fix(pca_ex01)
names(pca_ex01)[1]="Income"
library(shiny)
version
version
version
update.packages(ask = FALSE, checkBuilt = TRUE)
version
library(shiny)
R.version.string
shiny::runApp('App-1')
runApp('App-1')
runApp('App-1')
install.packages("DT")
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
ui <- fluidPage(
tags$head(
tags$style(HTML("
.bg-image {
width: 100%;
display: block;
margin-bottom: 15px;
}
body {
background-color: #f8f9fa;
}
.slider-panel {
background: white;
padding: 15px;
border-radius: 10px;
box-shadow: 0px 4px 6px rgba(0,0,0,0.1);
}
"))
),
# Background Image Before Slider
tags$img(src = "pic.jpg", class = "bg-image"),
titlePanel("ðŸŽ® Video Game Sales Explorer ðŸŽ®"),
sidebarLayout(
sidebarPanel(
div(class = "slider-panel",
sliderInput("yearInput", "Select Year Range:",
min = 1980, max = 2020, value = c(2000, 2015), step = 1)
)
),
mainPanel(
tabsetPanel(
tabPanel("ðŸ“ˆ Sales Trend",
h3("Global Sales Trends Over the Years"), # Title
plotOutput("salesTrendPlot")
),
tabPanel("ðŸ† Top Game & Publisher",
h3("Top-Selling Game and Publisher"), # Title
verbatimTextOutput("topGame"),
verbatimTextOutput("topPublisher"),
plotOutput("publisherSalesPlot")
),
tabPanel("ðŸ“ Game List",
h3("Top 10 Games Based on Filters"), # Title
tableOutput("gameTable")
)
)
)
)
)
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
runApp('VideoGameSalesApp')
shiny::runApp('VideoGameSalesApp')
shiny::runApp('video_games_app_final')
shiny::runApp('video_games_app_final')
shiny::runApp('video_games_app_final')
runApp('video_games_app_final')
shiny::runApp('video_games_app_final')
runApp('video_games_app_final')
times = c(3,4,5,6,7,8,9)
censor = c(1,1,1,0,1,0,1)
times = c(3,4,5,6,7,8,9)
censor = c(1,1,1,0,1,0,1)
library(survival, lib.loc = "C:/Program Files/R/R-4.4.2/library")
surv(times,censor)
library("survival")
surv(times,censor)
Surv(times,censor)
tt = Surv(times,censor)
tt
survfit(tt)
survfit(tt-1)
survfit(tt,1)
survfit(tt~1)
km = survfit(tt~1)
km
summary(km)
1/7
6/7
a=76
b=67
if(a>b)
{
c = a-b
print("condition a > b is TRUE")
print(paste("Difference between a, b is : ", c))
}
a=76
b=67
if(a>b)
{
c = a-b
print("condition a > b is TRUE")
print("Difference between a, b is : ", c)
}
#Subset observations (Rows)
filter(iris,Sepal.Length>7)
library('dplyr')
tbl_df(iris)
glimpse(iris)
View(iris)
iris %>% group_by(Species) %>%
summarise(avg=mean(Sepal.Width))%>%
arrange(avg)
#Subset observations (Rows)
filter(iris,Sepal.Length>7)
distinct(iris)
sample_frac(iris,0.5,replace = TRUE
)
select(iris,contains("."))
library(tidyr)
separate(storms,date,c("y","m","d"))
first(iris)
nth(iris)
5th(iris)
group_by(iris,Species)
library(tidyverse)
#1
#install.packages("openintro")
library(openintro)
library(tidyverse)
#1
#install.packages("openintro")
library(openintro)
#2
data("acs12")
acs_df = acs12
head(acs_df)
new = mutate(acs_df,new_var=income/1000)
new
#import libraries
library(shiny)
library(shinythemes)
library(ggplot2)
library(dplyr)
library(DT)
# Load dataset
df <- read.csv("data/video_games_sales_cleaned.csv")
setwd("D:/3rdyr/3rdyr_2ndsem/3rdyr_2nd_sem/ST 3011/16043/data")
# Load dataset
df <- read.csv("data/video_games_sales_cleaned.csv")
